I boka [The Big Switch: Rewiring the World, from Edison to Google](http://www.computerworld.com/article/2534133/infrastructure-management/q-a--nicholas-carr-on--the-big-switch--to-cloud-computing.html) fra 2008 hevdet Nicholas Carr at dataindustrien var inne i en tilsvarende transformasjon som ved etablering av strømnettet for 100 år siden, da industrien faset ut egen energiproduksjon til fordel for elektrisk kraft fra nettet. Drøye ti år etter at AWS lanserte EC2 og S3 som Infrastructure-as-a-Service, tilbyr nå _serverless_-tjenester ekte datakraft i nettskyen, frikoblet fra servere og infrastruktur. Når man ikke lenger forholder seg til infrastruktur elimineres den tradisjonelle basisdriften; _NoOps_. Dataindustrien går igjen bananas! Og det med god grunn!

# Serverless?
Aller først, to kjernepunkter:
* **Serverless-applikasjoner kjører fortsatt på datamaskiner**. En funksjon som kjører i AWS Lambda benytter naturligvis AWS-servere. Poenget er at hele infrastrukturen er usynlig for applikasjonen; den forholder seg kun til serverless-plattformen for å kjøre. Skalering og oppetid håndteres uten at man selv må legge til eller fjerne servere. Betaling baseres på faktisk bruk av tjenesten, eksempelvis tidsforbruk, antall kjøringer eller dataoverføringsvolumer. 
* **Serverless er kun mulig i nettskyen**. Store virksomheter med sterke driftsmiljøer vil etablere interne "serverless"-plattformer. _Men de må fortsatt håndtere infrastrukturen!_ Dessuten er det vanskelig å se for seg hvordan interne driftsorganisasjoner skal kunne konkurrere med de store nettskyplattformene, for [hvem kan konkurrere med AWS?](https://open.bekk.no/hvem-kan-konkurrere-med-amazon-web-services)

## Function-as-a-Service (FaaS)
[AWS Lambda](https://aws.amazon.com/lambda/) er den mest kjente serverless-plattformen i kategorien _Function-as-a-Service (FaaS)_. Lambda-funksjonen, altså applikasjonen som kjører på AWS Lambda, er ren forretningslogikk implementert i Java, Node.js, C# eller Python. Den kan kjøres som resultat av hendelser i AWS-økosystemet, som svar på en forespørsel i en webapplikasjon eller utgjøre kjernefunksjonaliteten i _stream computing_ med Kinesis:
* [Jakten på fem tusen skatteberegninger i sekundet](https://open.bekk.no/jakten-pa-fem-tusen-skatteberegninger-i-sekundet) illustrerer sistnevnte variant med AWS DynamoDB, Kinesis og Lambda for skatteberegning.
* [Jakten på fem tusen KRYPTERTE skatteberegninger](https://open.bekk.no/jakten-pa-5000-krypterte-skatteberegninger) viser hvordan kryptering kan integreres med denne plattformen.
* [Referansearkitektur](https://github.com/awslabs/lambda-refarch-webapp) for en _Single Page App_ lastet fra AWS S3 som spør direkte mot Lambda-funksjoner via API Gateway ([illustrasjon](https://s3.amazonaws.com/awslambda-serverless-web-refarch/RefArch_BlogApp_Serverless.png)).  

[Google Cloud Functions](https://cloud.google.com/functions/), [Azure Functions](https://azure.microsoft.com/nb-no/services/functions/), [IBM OpenWhisk](https://developer.ibm.com/openwhisk/) og [Auth0 Webtask](https://webtask.io/) er eksempler på FaaS-plattformer fra andre nettskyleverandører, og [Fission](http://blog.kubernetes.io/2017/01/fission-serverless-functions-as-service-for-kubernetes.html) ble nylig lansert som en FaaS-plattform på toppen av Kubernetes.

OpenWhisk og Fission er eksempler på FaaS-plattformer man kan kjøre på egen infrastruktur. På veien ut i nettskyen kan dette gi mening i en overgangsperiode der man eksperimenterer med og bygger kompetanse på plattformene, eller har data og eksisterende systemer man integrerer med som ikke kan flyttes ut i skyen på kort sikt. Imidlertid bør dette være et steg på veien, ikke endestasjonen for FaaS i virksomheten. Det vil være vanskelig å forsvare kostnaden og kompleksiteten ved å drifte FaaS på intern infrastruktur sammenliknet med hva de store nettskyleverandørene tilbyr. Applikasjoner som ikke kan skysettes, for eksempel på grunn av Sikkerhetsloven, kan klargjøres for framtidig skysetting på en intern FaaS-plattform. For å klargjøre applikasjoner for skysetting bør man uansett følge det klassiske prinsippet om å holde forretningsdomenet fritt for plattformavhengigheter, kombinert med et mikrotjenestearkitekturmålbilde som et naturlig steg mot å ta i bruk FaaS-plattformer.

## AaaS, BaaS, CaaS...
Gode, gamle IaaS, PaaS og SaaS har blitt supplert med _altmulig_-as-a-Service. _Software-as-a-Service (SaaS)_ som Salesforce og Office 365 er de mest kjente eksemplene på, er forsåvidt driftede skytjenester, men SaaS-begrepet betegner primært produkter og hyllevare. Etter hvert som [alt blir driftede skytjenester](https://en.wikipedia.org/wiki/As_a_service) vil _aaS_-begrepene miste mening. Her er imidlertid noen mer eller mindre etablerte kategorier:
* _AaaS - Authentication as a Service_ omfatter autentisering av brukere, multifaktor-autentisering, _Single Sign-On (SSO)_ og liknende (også kjent som _Identity-as-a-Service_ eller _IDaaS_). BEKK har eksempelvis tatt i bruk [Auth0](https://auth0.com/) for autentisering.
* _BaaS - Backend-as-a-Service_ gir web- og mobilapper tjenester for lagring og prosessering, i tillegg til funksjonalitet for brukerhåndtering, integrasjon med sosiale medier, push-notifikasjon og andre standard tjenester.
* _CaaS - Containers-as-a-Service_ betegner typisk tjenester for å bruke Docker-containere som abstraksjon for utrulling av applikasjoner, og tilbyr gjerne orkestrering av clustere, tjenesteoppslag, lastbalansering, _fail-over_ og liknende funksjonalitet. CaaS kan ses på som en mellomting mellom PaaS og virtualisering med IaaS. [Kubernetes](https://kubernetes.io/) er den mest kjente orkestreringsplattformen, og de tre store nettskyleverandørene tilbyr CaaS via henholdsvis [Google Container Engine](https://cloud.google.com/container-engine/), [Azure Container Service](https://azure.microsoft.com/en-us/services/container-service/) og [Amazon EC2 Container Service](https://aws.amazon.com/ecs/).

[Serverless Architectures av Mike Roberts (på Martin Fowlers blogg)](https://martinfowler.com/articles/serverless.html) gir en grundig gjennomgang av disse konseptene. Om du sitter igjen med inntrykk av at serverless er de nye _stored procedures_ kan du lese Adrian Cockcrofts [Evolution of Business Logic from Monoliths through Microservices, to Functions](https://read.acloud.guru/evolution-of-business-logic-from-monoliths-through-microservices-to-functions-ff464b95a44d#.fi743u6lv) for et mer spenstig perspektiv, eller titte på ([tilhørende video fra microXchg 2017]( https://www.youtube.com/watch?v=ZgxZCXouBkY)).

## Driftede skytjenester (Managed cloud services)
En annen type serverless-plattformer er _driftede skytjenester_ eller _managed cloud services_. Dette er tjenester som støtter et spesifikt behov, der skyleverandøren står for basisdriften. Et utmerket eksempel er [Google BigQuery](https://cloud.google.com/bigquery/), som tilbyr et moderne datavarehus i nettskyen med et SQL-grensesnitt for analyse. Som bruker av BigQuery har du ikke noe forhold til den underliggende infrastrukturen; Google Cloud Platform sørger for skalerbarhet og tilgjengelighet, og du betaler for bruk i form av lagring, _streaming inserts_ og spørringer. En slik driftet skytjeneste ville for eksempel passe som hånd i hanske når Skatteetaten skal etablere plattform for analyse og scoring; se [Skatteetatens analyseplattform i Google Cloud](https://open.bekk.no/[skatteetatDataflowens-analyseplattform-i-google-cloud).

Et annet illustrerende eksempel er fra [Datainn](https://open.bekk.no/trafikkmeldinger-og-datainn) hos Statens vegvesen. Her benyttes Elasticsearch for lagring, søk og aggregering av mange milliarder hendelser som representerer kjøretøy som passerer målestasjoner på veinettet i Norge. Sommeren 2016 testet to BEKK-sommervikarer BigQuery (som alternativ til Vegvesenets interne Elasticsearch-cluster) for å generere en kompleks rapport med mye data. Selve oppsettet av spørringene og rapporten var rimelig rett fram etter litt knot med overføring av relativt store datamengder. Testen viste at de samme aggregeringene og rapporten kunne kjøres på litt kortere tid i BigQuery. Og selv om det ikke er poenget, havnet disse kjøringene på gratiskvoten i BigQuery; stordata i norsk sammenheng er ikke nødvendigvis store for de globale nettskyplattformene. Det overordnede funnet var at BigQuery sannsynligvis kan erstatte den interne Elasticsearch-riggen for rapportgenerering, og dermed kan man la Google håndtere infrastruktur, skalering og oppetid.

[Amazon Simple Storage Service (S3)](https://aws.amazon.com/s3/) var kanskje det første eksemplet på en driftet skytjeneste. S3 tilbyr tilnærmet ubegrenset lagring med høy oppetid der man betaler for faktisk bruk. AWS tilbyr i dag en rekke driftede skytjenester, som [DynamoDB](https://aws.amazon.com/dynamodb/), [Kinesis](https://aws.amazon.com/kinesis) og [Rekognition](https://aws.amazon.com/rekognition/). De fleste tjenestene i Google Cloud Platform er også driftede skytjenester, eksempelvis [Cloud Dataflow](https://cloud.google.com/dataflow/) og [Cloud Machine Learning](https://cloud.google.com/ml/). Ikke minst er det verdt å nevne nylig lanserte [Cloud Spanner](https://cloud.google.com/spanner/); en relasjonsdatabase som tilbyr sterk konsistens (lineariserbarhet), horisontal skalerbarhet og høy oppetid (les gjerne [Spanner, TrueTime and the CAP Theorem](https://research.google.com/pubs/pub45855.html)). Azure [Data Lake-analyse](https://azure.microsoft.com/nb-no/services/data-lake-analytics/) og [Watson Analytics](https://www.ibm.com/us-en/marketplace/watson-analytics) er eksempler på driftede skytjenester fra Microsoft og IBM.

Kjennetegnene for driftede skytjenester er at man ikke forholder seg til den underliggende infrastrukturen, at tilgjengelighet, redundans og skalering håndteres sømløst av skyplattformen, og man betaler for faktisk bruk. I lys av dette er for eksempel [Amazon Elasticsearch Service](https://aws.amazon.com/elasticsearch-service/) en avart der man må forholde seg til CPU-instanser og minne for den driftede skytjenesten. _Platform-as-a-Service_-varianter som [AWS Elastic Beanstalk](https://aws.amazon.com/elasticbeanstalk/) og [Azure App Service](https://azure.microsoft.com/nb-no/services/app-service/) når heller ikke helt opp ettersom man må forholde seg til underliggende ressurser som CPU og minne. Tilsvarende gjelder også for tjenester som [Google Container Engine (Kubernetes)](https://cloud.google.com/container-engine/) og [Heroku](https://www.heroku.com/). PaaS og CaaS kan gi stor verdi og være bra valg i mange tilfeller, men de er ikke rene serverless-plattformer. 

## Mørke skyer på serverless-himmelen?
Her er noen vanlige innvendinger mot serverless-plattformene:
* _Serverless er umodent_. Driftede skytjenester som AWS S3 og Google BigQuery har lang fartstid. FaaS-plattformer er ikke like modne. Google Functions er for eksempel fremdeles i alfa-versjon, mens AWS Lambda er produksjonskvaliet.  Vær uansett klar for rivende utvikling på dette området i tiden framover.
* _Serverless låser deg til en proprietær plattform_. Dette varierer fra tjeneste til tjeneste. Eksemplet med [skatteberegninger](https://open.bekk.no/jakten-pa-fem-tusen-skatteberegninger-i-sekundet) viser hvor viktig det er å holde forretningslogikken fri for infrastruktur. Med et fåtall kodelinjer kunne den eksisterende Java-applikasjonen kjøres i AWS Lambda. Det er uansett smart å ha en plan for migrering til en alternativ plattform, både for prosessering og datalagring.
* _Serverless gjør utvikling og feilsøking vanskelig_. Igjen vil dette variere fra tjeneste til tjeneste. Applikasjonsutviklere foretrekker gjerne å arbeide på egen datamaskin, og manglende verktøy og innsyn i utviklings-, test- og produksjonsmiljøer gjør utvikling og feilsøking vanskelig. Prinsippet om å holde forretningslogikken fri for plattformavhengigheter gjelder også her, slik at man kan utvikle, teste og feilsøke uavhengig av FaaS-plattformen. Samtidig vil utviklingsarkitekturen, verktøystøtten og logging/overvåkning for serverless-plattformene være en viktig prioritet for skyleverandørene framover. AWS Lambda har eksempelvis allerede i dag god støtte for automatisert utrulling, logging og overvåkning, versjonering og integrasjon med IDEer som Eclipse.
* _Serverless gir dårlig kontroll på ytelse_. Kontrollen ligger hos skyleverandøren, men de er ansvarlig for å overholde SLAene sine. En serverless-plattform som ikke leverer som forventet, vil miste tillit og markedsandel. Som bruker av serverlessplattformen er det fortsatt sentralt å verifisere at behovene er tilfredsstilt ved å teste og monitorere applikasjonene.
* _Serverless gjør at vi mister kontroll på infrastrukturen_. På samme måte som sagbrukene måtte pensjonere [oppgangssaga](https://no.wikipedia.org/wiki/Oppgangssag) til fordel for elektrisk kraft, vil vi måtte gi slipp på infrastrukturen.

Serverless kommer med sine føringer og begrensninger, og man mister kontroll og fleksibilitet på infrastrukturnivå. Godt håndverk er en forutsetning også for å lykkes med serverless, inkludert oversikt over problemstillingene nevnt ovenfor. Nytten ved å ta i bruk serverless vil med stor sannsynlighet overgå kostnaden i langt de fleste sammenhengene.

# NoOps, LessOps, DifferentOps, DevOps
En ren _serverless_-løsning har ikke noe direkte forhold til infrastruktur som maskinvare, operativsystem eller nettverk. Dette har ført til _NoOps_-begrepet; _når det ikke lenger er noe å drifte, trengs heller ikke drift_. Påstanden er helt korrekt _for basisdrift_; å restarte servere, oppgradere maskiner og nettverksutstyr, i det hele tatt holde den fysiske infrastrukturen i gang er ikke lenger nødvendig. Eller, for å være mer presis; dette håndterer nettskyleverandøren slik at brukeren av _serverless_-plattformen istedet forholder seg til APIer og SLAer.

[Enkelte i DevOps-miljøet har reagert kraftig på NoOps-begrepet](https://devops.com/noops-devops-disaster-waiting-happen/). Den delen av DevOps-miljøet som i stor grad driver med automatisering av infrastruktur, IaaS og virtualisering kan bli marginalisert med tanke på sin investering i kompetanse og verktøy. Men Devops dreier seg om mye mer enn infrastruktur og basisdrift. Applikasjoner skal fortsatt utvikles, testets, versjoneres og releases uten nedetid med en automatisert utrullingskanal. Tjenestene må overvåkes, feil må logges, analyseres og rettes, data skal migreres skjemaer oppgraderes. Den snart tre år gamle [modenhetsmodellen for kontinuerlig leveranse](https://open.bekk.no/a-maturity-model-for-continuous-delivery) har kun enkelte infrastruktur-spesifikke poenger, som _Infrastructure as code_ (der intensjonen forøvrig er like gyldig for serverless; at man skal ha full kontroll på kjøretidsarkitekturen sin).  DevOps dreier seg om [kontinuerlig gevinstrealisering i et samarbeid mellom utvikling, drift, forretningssiden og sluttbrukerne](https://open.bekk.no/usrbizdevops), og om å [slutte med IT-prosjekter](http://open.bekk.no/slutt-med-it-prosjekter) til fordel for produktutvikling i et livssyklusperspektiv. 

NoOps understreker at det er på tide å slutte med basisdrift av egen infrastruktur og heller ta i bruk driftede skytjenester eller serverless-plattformer. Men applikasjonsdrift, overvåkning, kvalitetskontroll, feilretting, backup og restore vil ikke forsvinne. Noen bruker derfor heller begrepene _DifferentOps_ eller _LessOps_. DevOps-miljøet burde omfavne serverless-bevegelsen fordi den gjør at DevOps-målsetningene kan nås raskere og enklere.

# En titt i krystallkula
Jeg er ubetinget skeptisk til å spekulere om slike ting som sluttbrukerbehov og framtidig gjenbruk ved utvikling av programvare, og burde derfor avstå fra å spå om framtida. Allikevel har jeg en sterk magefølelse for at serverless og driftede skytjenester kommer til å dominere dataindustrien. Min favorittstrategikonsulent [Simon Wardley](https://twitter.com/swardley/status/799420770875277313) - han beskriver seg selv som en _recovering management consultant_ - bruker kart for å forstå historien, navigere samtiden og ta beslutninger om framtiden. I [Why the fuss about serverless?](https://hackernoon.com/why-the-fuss-about-serverless-4370b1596da0#.5acl5oj64) beskriver han overgangen fra 90-tallets monolitter på egen infrastruktur, via datakraft i nettskyen og mikrotjenester til funksjonsplattformer som AWS Lambda. Kjernen i artikkelen er at etterhvert som serverless-paradigmet uungåelig utvikler seg fra oppfinnelse til industrialisert produkt, vil man bli i stand til å _overvåke både kost og inntekt per funksjon_. Digitaliserte virksomheter som utnytter denne egenskapen vil være i en egen divisjon med tanke på å maksimere inntekt og minimalisere kostnader. Slike paradigmeskifter tar vanligvis 10-15 år ifølge Wardley og minner om at AWS lanserte EC2 i 2006. Dersom kartet stemmer med terrenget vil serverless være dominerende rundt 2025.

Serverless representerer overgangen til å konsumere ekte datakraft i nettskyen. Forvent at det skjer mye på dette området i månedene og årene framover. Ikke vent til 2025 med å skrote møllehjulet! Her er flere artikler og ressurser som kan sette deg på rett spor:
* [Debunking Serverless Myths](https://read.acloud.guru/debunking-serverless-myths-cc329460d061#.83pe5gcs1) - Peter Sbarski
* [Disruptive Serverless](https://medium.com/@PaulDJohnston/disruptive-serverless-ddb417ebdd15#.uly0g4htd)
* [Amazon is eating the software (which is eating the world)](https://hackernoon.com/amazon-is-eating-the-software-which-is-eating-the-world-738888fb9e82#.ofreimnvj) - Simon Wardley
* [Serverless Architectures on AWS](https://www.manning.com/books/serverless-architectures-on-aws?a_aid=serverless-architectures-on-aws&a_bid=145280de) - Bok av Peter Sbarski
* [Serverless Technologies & Architectures](https://github.com/ServerlessHeroes/serverless-resources)
* [Serverless Oslo](https://www.meetup.com/Serverless-Oslo/) - Meetup i Oslo
* [Serverlessconf](http://serverlessconf.io/) - Serverless-konferanser i London, New York, Tokya og Austin
